{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle link\n",
    "https://www.kaggle.com/datasets/denkuznetz/traffic-accident-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> loading data in </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_traffic_accident_prediction1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Processing data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working out total null values within each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    print(f\"{column} total null values: {sum(data[column].isnull())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting columns into a integer and not a float\n",
    "data['Driver_Age'] = data['Driver_Age'].astype(int)\n",
    "data['Number_of_Vehicles'] = data['Number_of_Vehicles'].astype(int)\n",
    "data['Driver_Experience'] = data['Driver_Experience'].astype(int)\n",
    "data['Driver_Alcohol'] = data['Driver_Alcohol'].astype(int)\n",
    "data['Traffic_Density'] = data['Traffic_Density'].astype(int)\n",
    "data['Accident'] = data['Accident'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\"> data visualisation/understanding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 >Sorting out age into categories </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working out min and max in age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum age: \",data['Driver_Age'].min())\n",
    "print(\"Maximum age: \",data['Driver_Age'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[18,25,35,45,55,69]\n",
    "ageGroupLabels = ['18-25','26-35','36-45','46-55','56-69']\n",
    "\n",
    "ageGroups = pd.cut(data['Driver_Age'], bins, labels=ageGroupLabels)\n",
    "\n",
    "print(ageGroups.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plotting the data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">Weather and age visualisation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working out the proportion of each type of condiction\n",
    "\n",
    "fig,ax = plt.subplots(1,2)\n",
    "\n",
    "wordLabels = [\"Clear\",\"Rainy\",\"Foggy\",\"Snowy\",\"Stormy\"]\n",
    "totalWordArr = np.array([]).astype(int)\n",
    "\n",
    "for word in wordLabels:\n",
    "    totalWordArr = np.append(totalWordArr,sum((data['Weather'] == word) == True))\n",
    "    #print(f\"Total amount of rows for {word} {sum((data['Weather'] == word) == True)}\")\n",
    "\n",
    "\n",
    "ax[0].pie(totalWordArr, labels=wordLabels, autopct=\"%1.1f%%\")\n",
    "ax[0].set_title(\"Weather distribution\")\n",
    "\n",
    "\n",
    "ageGroupsCounts = ageGroups.value_counts()\n",
    "ax[1].pie(ageGroupsCounts, labels=ageGroupsCounts.index,autopct=\"%1.1f%%\")\n",
    "ax[1].set_title(\"Age distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">Traffic density and number of vechicles distribution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrafficDensitylabels = [\"Low\",\"Moderate\",\"High\"]\n",
    "\n",
    "trafficDensityCategory = [0,1,2]\n",
    "NumberOfVechicalsCategory = np.array([]).astype(int)\n",
    "\n",
    "traffic_density_value_total = np.array([]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>working out labels for number of vechicals</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum amount of vechicals \",data['Number_of_Vehicles'].min())\n",
    "print(\"Maximum amount of vechicals \",data['Number_of_Vehicles'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumberOfVechicalsCategory = np.arange(start=data['Number_of_Vehicles'].min(),stop=data['Number_of_Vehicles'].max()+1,step=1)\n",
    "print(NumberOfVechicalsCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>working out the total for both traffic density and number of vechicals</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in trafficDensityCategory:\n",
    "    traffic_density_value_total = np.append(traffic_density_value_total,sum((data['Traffic_Density'] == category) == True))\n",
    "\n",
    "#print(data['Number_of_Vehicles'].value_counts(ascending=True))\n",
    "value_counts = data['Number_of_Vehicles'].value_counts(ascending=True)\n",
    "NumberVechicalTotal = np.array([(label,value_counts.get(label,0)) for label in np.arange(start=data['Number_of_Vehicles'].min(),stop=data['Number_of_Vehicles'].max()+1,step=1)])\n",
    "\n",
    "for _,value in NumberVechicalTotal:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax[0].bar(TrafficDensitylabels,traffic_density_value_total)\n",
    "ax[0].set_title(\"Traffic density\")\n",
    "\n",
    "\n",
    "xLabel_vechicle = NumberVechicalTotal[:,0]\n",
    "print(xLabel_vechicle)\n",
    "\n",
    "#ax[1].bar(NumberOfVechicalsCategory,data['Number_of_Vehicles'].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center>Vechicle type visualisaiton</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
